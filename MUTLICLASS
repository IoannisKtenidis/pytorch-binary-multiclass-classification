{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"cYNJx-WmevmM"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","import matplotlib.pyplot as plt\n","import joblib\n","from sklearn.preprocessing import OneHotEncoder\n","import random\n","RANDOM_SEED=42\n","from torch.utils.data import TensorDataset, DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1741875095669,"user":{"displayName":"Giannhs Ktenidhs","userId":"17293057494255079678"},"user_tz":-120},"id":"-BHoYKlhfAgM","outputId":"35410dd3-3ef3-4d61-fb5a-820abdd0e298"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 0.6084,  1.0300,  1.0300,  ..., -0.1891,  0.5931,  1.1801],\n","        [ 0.6084,  0.8656,  0.8656,  ..., -0.1874,  0.5715,  1.2152],\n","        [ 0.6084,  1.0300,  1.0300,  ..., -0.1873,  0.5679,  1.1670],\n","        ...,\n","        [-1.3890, -1.0248, -1.0248,  ..., -0.2349, -0.7311, -0.9408],\n","        [-1.3890, -1.0248, -1.0248,  ..., -0.2349, -0.7311, -0.9408],\n","        [-1.3890, -1.0248, -1.0248,  ..., -0.2349, -0.7311, -0.9408]])\n"]}],"source":["# Load and preprocess the data\n","df = pd.read_csv(\"AImodelclass_pytorch.csv\")\n","\n","\n","remove_cols = ['Label', 'Timestamp', 'DRB.RlcDelayUl']\n","train_features = [col for col in df.columns if col not in remove_cols]\n","\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(df[train_features].values)\n","X = torch.tensor(X_scaled, dtype=torch.float)\n","print (X)\n","y = torch.tensor(df['Label'].values, dtype=torch.float).view(-1, 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aTDts5AwfApu"},"outputs":[],"source":["# Split the data\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, train_size=0.70, test_size=0.30, random_state=42, shuffle=True\n",")\n","\n","X_train = TensorDataset(X_train, y_train)\n","X_test = TensorDataset(X_test, y_test)\n","train_loader = DataLoader(X_train, batch_size=4, shuffle=True)\n","test_loader = DataLoader(X_test, batch_size=4, shuffle=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PpuqzcU7fAxI"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [100/2000], Loss: 0.0000, Accuracy: 0.0000, Accuracy: 0.0000\n","Epoch [200/2000], Loss: 0.0000, Accuracy: 0.0000, Accuracy: 0.0000\n","Epoch [300/2000], Loss: 0.0001, Accuracy: 0.0000, Accuracy: 0.0000\n","Epoch [400/2000], Loss: 0.0000, Accuracy: 1.0000, Accuracy: 0.0000\n","Epoch [500/2000], Loss: 0.8911, Accuracy: 0.0000, Accuracy: 0.0000\n","Epoch [600/2000], Loss: 0.0000, Accuracy: 1.0000, Accuracy: 0.0000\n","Epoch [700/2000], Loss: 0.0000, Accuracy: 1.0000, Accuracy: 0.0000\n","Epoch [800/2000], Loss: 0.0000, Accuracy: 1.0000, Accuracy: 0.0000\n","Epoch [900/2000], Loss: 0.0026, Accuracy: 1.0000, Accuracy: 0.0000\n","Epoch [1000/2000], Loss: 0.0000, Accuracy: 1.0000, Accuracy: 0.0000\n","Epoch [1100/2000], Loss: 0.0000, Accuracy: 0.0000, Accuracy: 0.0000\n","Epoch [1200/2000], Loss: 0.0024, Accuracy: 1.0000, Accuracy: 0.0000\n","Epoch [1300/2000], Loss: 0.0024, Accuracy: 1.0000, Accuracy: 0.0000\n","Epoch [1400/2000], Loss: 0.0000, Accuracy: 0.0000, Accuracy: 0.0000\n","Epoch [1500/2000], Loss: 0.0028, Accuracy: 1.0000, Accuracy: 0.0000\n","Epoch [1600/2000], Loss: 0.0000, Accuracy: 0.0000, Accuracy: 0.0000\n","Epoch [1700/2000], Loss: 0.0000, Accuracy: 1.0000, Accuracy: 0.0000\n","Epoch [1800/2000], Loss: 0.0000, Accuracy: 1.0000, Accuracy: 0.0000\n","Epoch [1900/2000], Loss: 0.0000, Accuracy: 1.0000, Accuracy: 0.0000\n","Epoch [2000/2000], Loss: 0.0029, Accuracy: 1.0000, Accuracy: 0.0000\n"]}],"source":["# Set a random seed for reproducibility\n","torch.manual_seed(42)\n","\n","# Define the model with dropout for regularization\n","model = nn.Sequential(\n","    nn.Linear(15, 7),\n","    nn.ReLU(),\n","    # nn.Dropout(0.5),            # 50% dropout\n","    nn.Linear(7, 3),\n","    nn.ReLU(),\n","    # nn.Dropout(0.5),            # 50% dropout\n","    nn.Linear(3, 1),\n","\n",")\n","\n","# Use BCEWithLogitsLoss (no final Sigmoid in the model)\n","loss_fn = nn.MSELoss()\n","\n","# Use Adam with weight decay for L2 regularization\n","optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0)\n","\n","# Lists to store loss and accuracy\n","loss_history = []\n","accuracy_history = []\n","accuracy_test_history = []\n","\n","\n","# Train the model with early stopping potential (not implemented here but recommended)\n","num_epochs = 2000\n","for epoch in range(num_epochs):\n","    for batch_idx, (inputs, targets) in enumerate(train_loader):\n","      model.train()\n","      optimizer.zero_grad()\n","      logits = model(inputs)\n","      loss_value = loss_fn(logits, targets)\n","      loss_value.backward()\n","      optimizer.step()\n","      #print(targets)\n","      #print(logits)\n","      #break\n","      # Calculate accuracy\n","      #predictions = torch.sigmoid(logits)\n","      predicted_labels = (logits \u003e= 0.5).int()\n","      #predictions = logits\n","      accuracy_train = accuracy_score(targets, predicted_labels)\n","\n","\n","\n","\n","      #\"\"\"\n","    if (epoch + 1) % 100 == 0:\n","      # predictions = torch.sigmoid(logits)\n","        #predicted_labels = (predictions \u003e= 0.5).int()\n","        #accuracy_train = accuracy_score(y_train, predicted_labels)\n","\n","        # Store metrics\n","        loss_history.append(loss_value.item())\n","        accuracy_history.append(accuracy_train)\n","\n","        # Evaluation\n","        model.eval()\n","        #with torch.no_grad():\n","        for batch_idx, (inputs, targets) in enumerate(test_loader):\n","          test_predictions = model(inputs)\n","          #test_predictions = torch.sigmoid(test_logits)\n","          #test_predictions = test_logits\n","          test_predicted_labels = (test_predictions \u003e= 0.5).int()\n","          accuracy_test = accuracy_score(targets, test_predicted_labels)\n","        accuracy_test_history.append(accuracy_test)\n","        #print(test_predicted_labels)\n","\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss_value.item():.4f}, Accuracy: {accuracy_train:.4f}, Accuracy: {accuracy_test:.4f}')\n","\n","          #print(test_predicted_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dia6rSJdiET9"},"outputs":[],"source":["test_accuracy = accuracy_score(y_test, test_predicted_labels)\n","test_precision = precision_score(y_test, test_predicted_labels)\n","test_recall = recall_score(y_test, test_predicted_labels)\n","test_f1 = f1_score(y_test, test_predicted_labels)\n","\n","print(\"Accuracy:\", test_accuracy)\n","print(\"Precision:\", test_precision)\n","print(\"Recall:\", test_recall)\n","print(\"F1 Score:\", test_f1)\n","print(accuracy_test)\n","print(len(accuracy_test_history))\n","print(len(accuracy_history))\n","print(accuracy_test_history)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_RQpi5nRiGSs"},"outputs":[],"source":["#\"\"\"\n","# Plot Loss vs. Epoch\n","plt.figure(figsize=(10, 5))\n","plt.plot(range(40), loss_history, label='Loss', color='blue')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Loss vs. Epoch')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","#\"\"\"\n","\n","# Plot Accuracy vs. Epoch\n","plt.figure(figsize=(10, 5))\n","plt.plot(range(40), accuracy_history, label='Accuracy', color='green')\n","plt.plot(range(40), accuracy_test_history, label='Accuracy', color='red')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.title('Accuracy vs. Epoch')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VUWoHAD4iJWX"},"outputs":[],"source":["# Save just the state dictionary\n","torch.save(model.state_dict(), 'model_state.pth')\n","\n","# Or save the entire model (less flexible, but easier to load)\n","torch.save(model, 'model_full.pth')\n","\n","# Save the fitted scaler\n","joblib.dump(scaler, 'scaler.pkl')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPRXANQnyAklMAhM5pxmGQW","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}